% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_tune_classifier_spark.R
\name{auto_tune_classifier_spark}
\alias{auto_tune_classifier_spark}
\title{Automatically Tune and Train Multiple Classification Models with Spark Distribution}
\usage{
auto_tune_classifier_spark(
  sc,
  X_train,
  Y_train,
  algorithms,
  cv_folds = 5,
  n_evals = 50,
  model_tuning = "all",
  seed = 123,
  verbose = TRUE
)
}
\arguments{
\item{sc}{Active Spark connection from spark_connect()}

\item{X_train}{Training features data.frame or matrix}

\item{Y_train}{Training target vector (binary classification: 0/1 or logical, will be converted to factor)}

\item{algorithms}{Named list where each element contains:
- learner: mlr3 learner ID (e.g., "classif.ranger", "classif.xgboost")
- param_space: paradox::ParamSet defining search space (optional if model_tuning = "untuned")
- measure: mlr3 measure ID (e.g., "classif.auc", "classif.prauc")
- predict_type: prediction type - "prob" for probabilities or "response" for class labels (default: "prob")}

\item{cv_folds}{Number of cross-validation folds for tuning (default: 5)}

\item{n_evals}{Number of random search iterations per algorithm (default: 50)}

\item{model_tuning}{Character indicating which models to return: "untuned", "tuned", or "all" (default: "all")}

\item{seed}{Integer seed for reproducibility (default: 123). When set, ensures reproducible results.}

\item{verbose}{Logical indicating whether to print progress messages (default: TRUE)}
}
\value{
List containing:
  - tuned: List of tuned mlr3 learners (if model_tuning is "tuned" or "all")
  - untuned: List of untuned mlr3 learners (if model_tuning is "untuned" or "all")
  - tuning_results: List of tuning results for each algorithm (if model_tuning is "tuned" or "all")
  - cluster_info: Information about the cluster configuration
}
\description{
This function distributes hyperparameter search across Spark executors using spark_apply,
maximizing cluster utilization for large-scale tuning operations.
}
\examples{
\dontrun{
# Connect to Spark cluster
library(sparklyr)
sc <- spark_connect(method = "databricks")

# Prepare data
X_train <- iris[, 1:4]
Y_train <- ifelse(iris$Species == "setosa", 1, 0)

# Define algorithms
algorithms <- list(
  ranger = list(
    learner = "classif.ranger",
    param_space = paradox::ps(
      num.trees = paradox::p_int(100, 500),
      mtry.ratio = paradox::p_dbl(0.1, 1),
      min.node.size = paradox::p_int(1, 10)
    ),
    measure = "classif.auc",
    predict_type = "prob"  # Required for classif.auc
  )
)

# Train models
results <- auto_tune_classifier_spark(
  sc = sc,
  X_train = X_train,
  Y_train = Y_train,
  algorithms = algorithms,
  cv_folds = 5,
  n_evals = 50,
  model_tuning = "all",
  seed = 123
)

# Access models
tuned_model <- results$tuned$ranger
untuned_model <- results$untuned$ranger

# Make predictions
predictions <- tuned_model$predict_newdata(newdata = iris[1:10, 1:4])

# Disconnect
spark_disconnect(sc)
}

}
