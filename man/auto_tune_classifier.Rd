% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_tune_classifier.R
\name{auto_tune_classifier}
\alias{auto_tune_classifier}
\title{Automatically Tune Binary Classification Algorithms}
\usage{
auto_tune_classifier(
  X_train,
  Y_train,
  algorithms,
  cv_folds = 2,
  n_evals = 15,
  cores_to_use = max(1, detectCores() - 1),
  model_tuning = "all",
  spark_connection = NULL
)
}
\arguments{
\item{X_train}{Matrix or data frame of training features}

\item{Y_train}{Vector of training outcomes (binary classification: 0/1 or logical)}

\item{algorithms}{Named list of algorithms to tune. Names must be "ranger" and/or "xgboost".
Each element should contain:
- param_space: ps() object defining search space
- measure: tuning criterion (e.g., "classif.prauc")}

\item{cv_folds}{Number of cross-validation folds for tuning (default: 2)}

\item{n_evals}{Number of parameter evaluations for tuning (default: 15)}

\item{cores_to_use}{Number of cores to use for parallel processing (default: detectCores() - 1)}

\item{model_tuning}{Character indicating which models to return: "untuned", "tuned", or "all" (default: "all")}

\item{spark_connection}{Optional sparklyr connection object for distributed processing. If provided,
parameter search evaluations will be distributed across Spark executors.
Defaults to 18 executors with 8 cores each if configuration cannot be detected.}
}
\value{
Depends on model_tuning parameter:
        - "all": List with 'tuned' and 'untuned' elements
        - "tuned": Named list of tuned learners only
        - "untuned": Named list of untuned learners only
}
\description{
This function automatically tunes ranger (Random Forest) and/or xgboost algorithms
using specified search spaces and optimization criteria for binary classification.
}
\examples{
\dontrun{
# Define search spaces
algorithms <- list(
  ranger = list(
    param_space = paradox::ps(
      num.trees = paradox::p_int(100, 500),
      mtry.ratio = paradox::p_dbl(0.1, 1),
      min.node.size = paradox::p_int(1, 10)
    ),
    measure = "classif.prauc"
  ),
  xgboost = list(
    param_space = paradox::ps(
      nrounds = paradox::p_int(50, 200),
      eta = paradox::p_dbl(0.01, 0.3, logscale = TRUE),
      max_depth = paradox::p_int(3, 8)
    ),
    measure = "classif.auc"
  )
)

# Tune algorithms
results <- auto_tune_classifier(X_train, Y_train, algorithms)
}

}
