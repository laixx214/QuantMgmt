% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_tune_classifier.R,
%   R/auto_tune_classifier_spark.R
\name{auto_tune_classifier}
\alias{auto_tune_classifier}
\title{Automatically Tune Binary Classification Algorithms}
\usage{
auto_tune_classifier(
  sc,
  X_train,
  y_train,
  algorithms,
  cv_folds = 5,
  n_evals = 50,
  model_tuning = "all",
  seed = 42,
  verbose = TRUE
)

auto_tune_classifier(
  sc,
  X_train,
  y_train,
  algorithms,
  cv_folds = 5,
  n_evals = 50,
  model_tuning = "all",
  seed = 42,
  verbose = TRUE
)
}
\arguments{
\item{sc}{Active Spark connection from spark_connect()}

\item{X_train}{Training features data.frame}

\item{y_train}{Training target vector (will be converted to factor)}

\item{algorithms}{Named list where each element contains:
- learner: mlr3 learner ID (e.g., "classif.ranger", "classif.xgboost")
- param_space: paradox::ParamSet defining search space (optional if model_tuning = "untuned")
- measure: mlr3 measure ID (e.g., "classif.auc", "classif.prauc")}

\item{cv_folds}{Number of cross-validation folds (default: 5)}

\item{n_evals}{Number of random search iterations per algorithm (default: 50)}

\item{model_tuning}{Character indicating which models to return: "untuned", "tuned", or "all" (default: "all")}

\item{seed}{Random seed for reproducibility (default: 42)}

\item{verbose}{Print progress messages (default: TRUE)}

\item{Y_train}{Vector of training outcomes (binary classification: 0/1 or logical)}

\item{cores_to_use}{Number of cores to use for parallel processing (default: detectCores() - 1)}

\item{verbose_parallel}{Logical indicating whether to enable verbose output for parallel processing
diagnostics (default: FALSE). When TRUE, enables future.debug output.}
}
\value{
Depends on model_tuning parameter:
        - "all": List with 'tuned' and 'untuned' elements
        - "tuned": Named list of tuned learners only
        - "untuned": Named list of untuned learners only

List containing:
  - tuned: List of tuned mlr3 learners (if model_tuning is "tuned" or "all")
  - untuned: List of untuned mlr3 learners (if model_tuning is "untuned" or "all")
  - tuning_results: List of tuning results for each algorithm (if model_tuning is "tuned" or "all")
  - cluster_info: Information about the cluster configuration
}
\description{
This function automatically tunes ranger (Random Forest) and/or xgboost algorithms
using specified search spaces and optimization criteria for binary classification.

This function distributes hyperparameter search across Spark executors using spark_apply,
maximizing cluster utilization for large-scale tuning operations.
}
\examples{
\dontrun{
# Define search spaces
algorithms <- list(
  ranger = list(
    param_space = paradox::ps(
      num.trees = paradox::p_int(100, 500),
      mtry.ratio = paradox::p_dbl(0.1, 1),
      min.node.size = paradox::p_int(1, 10)
    ),
    measure = "classif.prauc"
  ),
  xgboost = list(
    param_space = paradox::ps(
      nrounds = paradox::p_int(50, 200),
      eta = paradox::p_dbl(0.01, 0.3, logscale = TRUE),
      max_depth = paradox::p_int(3, 8)
    ),
    measure = "classif.auc"
  )
)

# Tune algorithms
results <- auto_tune_classifier(X_train, Y_train, algorithms, seed = 123)
}

}
