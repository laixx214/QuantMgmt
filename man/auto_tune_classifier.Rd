% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/auto_tune_classifier.R
\name{auto_tune_classifier}
\alias{auto_tune_classifier}
\title{Automatically Tune Binary Classification Algorithms}
\usage{
auto_tune_classifier(
  X_train,
  Y_train,
  algorithms,
  cv_folds = 2,
  n_evals = 15,
  cores_to_use = max(1, detectCores() - 1),
  model_tuning = "all",
  verbose = TRUE,
  seed = 123
)
}
\arguments{
\item{X_train}{Matrix or data frame of training features}

\item{Y_train}{Vector of training outcomes (binary classification: 0/1 or logical)}

\item{algorithms}{Named list of algorithms to tune. Each element should contain:
- learner: mlr3 learner ID (e.g., "classif.ranger", "classif.xgboost")
- param_space: paradox::ParamSet defining search space (optional if model_tuning = "untuned")
- measure: tuning criterion (e.g., "classif.prauc", "classif.auc")
- predict_type: prediction type - "prob" for probabilities or "response" for class labels (default: "prob")}

\item{cv_folds}{Number of cross-validation folds for tuning (default: 2)}

\item{n_evals}{Number of parameter evaluations for tuning (default: 15)}

\item{cores_to_use}{Number of cores to use for parallel processing (default: detectCores() - 1)}

\item{model_tuning}{Character indicating which models to return: "untuned", "tuned", or "all" (default: "all")}

\item{verbose}{Logical indicating whether to enable verbose output for parallel processing
diagnostics (default: TRUE). When TRUE, enables future.debug output.}

\item{seed}{Integer seed for reproducibility (default: 123). When set, ensures reproducible results.}
}
\value{
List containing (structure depends on model_tuning parameter):
  - tuned: List of tuned mlr3 learners (if model_tuning is "tuned" or "all")
  - untuned: List of untuned mlr3 learners (if model_tuning is "untuned" or "all")
}
\description{
This function automatically tunes ranger (Random Forest) and/or xgboost algorithms
using specified search spaces and optimization criteria for binary classification.
}
\examples{
\dontrun{
# Define search spaces with explicit learner specification
algorithms <- list(
  ranger = list(
    learner = "classif.ranger",
    param_space = paradox::ps(
      num.trees = paradox::p_int(100, 500),
      mtry.ratio = paradox::p_dbl(0.1, 1),
      min.node.size = paradox::p_int(1, 10)
    ),
    measure = "classif.prauc",
    predict_type = "prob"  # Required for classif.prauc
  ),
  xgboost = list(
    learner = "classif.xgboost",
    param_space = paradox::ps(
      nrounds = paradox::p_int(50, 200),
      eta = paradox::p_dbl(0.01, 0.3, logscale = TRUE),
      max_depth = paradox::p_int(3, 8)
    ),
    measure = "classif.auc",
    predict_type = "prob"  # Required for classif.auc
  )
)

# Tune algorithms
results <- auto_tune_classifier(X_train, Y_train, algorithms, seed = 123)
}

}
